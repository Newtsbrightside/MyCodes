{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c5c40-a972-4ff6-8626-f3521fc016e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_neural_network.py\n",
    "# Neural Network Demo for Introduction to Neural Networks Class\n",
    "# Faculty of AI, UPH - Week 2 Session 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "print(\"Loading MNIST dataset...\")\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Let's look at a sample image\n",
    "def show_sample_images():\n",
    "    \"\"\"Display sample images from the dataset\"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "    for i in range(10):\n",
    "        row, col = i // 5, i % 5\n",
    "        image, label = train_dataset[i]\n",
    "        axes[row, col].imshow(image.squeeze(), cmap='gray')\n",
    "        axes[row, col].set_title(f'Label: {label}')\n",
    "        axes[row, col].axis('off')\n",
    "    plt.suptitle('Sample MNIST Images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Neural Network Architecture\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        # Input layer: 28*28 = 784 pixels\n",
    "        self.fc1 = nn.Linear(784, 128)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(128, 64)   # Second hidden layer  \n",
    "        self.fc3 = nn.Linear(64, 10)    # Output layer (10 digits)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the image: 28x28 -> 784\n",
    "        x = x.view(-1, 784)\n",
    "        \n",
    "        # First hidden layer with ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second hidden layer with ReLU activation\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Output layer (no activation here, will use CrossEntropyLoss)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = MNISTNet().to(device)\n",
    "print(f\"Model architecture:\\n{model}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        # Print progress\n",
    "        if batch_idx % 200 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data):5d}/{len(train_loader.dataset):5d} '\n",
    "                  f'({100. * batch_idx / len(train_loader):3.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Testing function\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, '\n",
    "          f'Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n')\n",
    "    \n",
    "    return test_loss, accuracy\n",
    "\n",
    "# Training loop\n",
    "def train_model(epochs=5):\n",
    "    train_losses, train_accuracies = [], []\n",
    "    test_losses, test_accuracies = [], []\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\n--- Epoch {epoch}/{epochs} ---\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, device, train_loader, optimizer, criterion, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        \n",
    "        # Test\n",
    "        test_loss, test_acc = test(model, device, test_loader, criterion)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch} Summary:\")\n",
    "        print(f\"  Train - Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"  Test  - Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies\n",
    "\n",
    "# Visualization functions\n",
    "def plot_training_history(train_losses, train_accuracies, test_losses, test_accuracies):\n",
    "    \"\"\"Plot training and testing metrics\"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    ax1.plot(epochs, test_losses, 'r-', label='Test Loss')\n",
    "    ax1.set_title('Training and Test Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot accuracies\n",
    "    ax2.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')\n",
    "    ax2.plot(epochs, test_accuracies, 'r-', label='Test Accuracy')\n",
    "    ax2.set_title('Training and Test Accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions(model, test_loader, num_samples=10):\n",
    "    \"\"\"Visualize model predictions on test data\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of test data\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "    \n",
    "    # Plot predictions\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        row, col = i // 5, i % 5\n",
    "        \n",
    "        # Get image, true label, and prediction\n",
    "        image = images[i].cpu().squeeze()\n",
    "        true_label = labels[i].item()\n",
    "        pred_label = predictions[i].item()\n",
    "        confidence = torch.softmax(outputs[i], dim=0)[pred_label].item()\n",
    "        \n",
    "        # Plot\n",
    "        axes[row, col].imshow(image, cmap='gray')\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        axes[row, col].set_title(f'True: {true_label}, Pred: {pred_label}\\nConf: {confidence:.2f}', \n",
    "                                color=color)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.suptitle('Model Predictions (Green=Correct, Red=Wrong)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_model_weights():\n",
    "    \"\"\"Visualize the weights of the first layer\"\"\"\n",
    "    # Get weights from first layer\n",
    "    first_layer_weights = model.fc1.weight.data.cpu().numpy()\n",
    "    \n",
    "    # Reshape to visualize as images (each neuron's weights as 28x28 image)\n",
    "    fig, axes = plt.subplots(8, 16, figsize=(16, 8))\n",
    "    \n",
    "    for i in range(128):  # 128 neurons in first hidden layer\n",
    "        row, col = i // 16, i % 16\n",
    "        weights = first_layer_weights[i].reshape(28, 28)\n",
    "        axes[row, col].imshow(weights, cmap='RdBu', vmin=-1, vmax=1)\n",
    "        axes[row, col].axis('off')\n",
    "        axes[row, col].set_title(f'N{i}', fontsize=8)\n",
    "    \n",
    "    plt.suptitle('First Layer Weights (What Each Neuron Looks For)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Show sample images\n",
    "    # print(\"1. Showing sample images...\")\n",
    "    # show_sample_images()\n",
    "    \n",
    "    # Train the model\n",
    "    # print(\"\\n2. Training the neural network...\")\n",
    "    # train_losses, train_accuracies, test_losses, test_accuracies = train_model(epochs=5)\n",
    "    \n",
    "    # Plot training history\n",
    "    # print(\"\\n3. Plotting training history...\")\n",
    "    # plot_training_history(train_losses, train_accuracies, test_losses, test_accuracies)\n",
    "    \n",
    "    # Show predictions\n",
    "    # print(\"\\n4. Visualizing predictions...\")\n",
    "    # visualize_predictions(model, test_loader)\n",
    "    \n",
    "    # Analyze model weights\n",
    "    # print(\"\\n5. Analyzing what the model learned...\")\n",
    "    # analyze_model_weights()\n",
    "    \n",
    "    # print(\"\\n🎉 Demo completed successfully!\")\n",
    "    # print(f\"Final test accuracy: {test_accuracies[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be80b0e-6c74-47e6-860d-088cb2e1d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample images\n",
    "print(\"1. Showing sample images...\")\n",
    "show_sample_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5fb82e-598d-45c2-a255-b9c91e136a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"\\n2. Training the neural network...\")\n",
    "train_losses, train_accuracies, test_losses, test_accuracies = train_model(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a84f9f-dfe0-41d7-a03e-cb191dc41463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "print(\"\\n3. Plotting training history...\")\n",
    "plot_training_history(train_losses, train_accuracies, test_losses, test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773346e-8552-4090-b65f-3463e5a3b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions\n",
    "print(\"\\n4. Visualizing predictions...\")\n",
    "visualize_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b0319-be2c-42c0-a97e-cc82ac69e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model weights\n",
    "print(\"\\n5. Analyzing what the model learned...\")\n",
    "analyze_model_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d9e7a-bf16-4918-8418-3cf7a96e6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🎉 Demo completed successfully!\")\n",
    "print(f\"Final test accuracy: {test_accuracies[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f625c7-5cca-4504-9032-a0a3c158f235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
